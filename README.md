# ğŸ”  Morse Code Decoder with LSTM

A deep learning model that **translates Morse code into English text** using a sequence-to-sequence architecture based on LSTMs.  
This project was built and tuned as part of a uni assignment for the course _Pattern Recognition in Audio Signals_.

---

## ğŸ’¡ Features

- ğŸ” **Bidirectional Morse encoder/decoder**
- ğŸ§  **LSTM-based neural network** with tunable architecture
- âš™ï¸ Experiments with:
  - Different hidden layer sizes (100 to 600 units)
  - Dropout regularization
  - Learning rates & batch sizes
- ğŸ“Š Visualization of training & validation accuracy/loss

---

## ğŸ–¼ï¸ Model Performance

### ğŸ§± Network Architectures

_Experiment showing how different LSTM layer sizes and dropout values impact performance._

![Architecture Accuracy](architecture_results.png)

### âš™ï¸ Learning Conditions

_Comparison of different batch sizes and learning rates._

![Learning Accuracy](learning_conditions.png)

---

## ğŸ“ˆ Key Results

- ğŸ§  600 hidden units = best performance (~98% accuracy by epoch 20)
- ğŸ›¡ Dropout 0.2 = prevents overfitting
- âš¡ Batch size 16 + learning rate 0.001 = fast and stable learning

---

## ğŸ“š Academic Context

Course: **Pattern Recognition in Audio Signals**  

Inspired by [Jozefowicz et al. (2015)](https://dl.acm.org/doi/10.5555/3045118.3045367)

---

## ğŸ’¡ Future Ideas

- Add support for variable-length Morse sequences
- Integrate attention mechanisms
- Build a simple user interface (web or CLI)

---

For educational purposes âœ¨
